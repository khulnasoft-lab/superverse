{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM54mpHhLjIk"
   },
   "source": [
    "# Superverse Quickstart\n",
    "\n",
    "---\n",
    "\n",
    "[![version](https://badge.fury.io/py/superverse.svg)](https://badge.fury.io/py/superverse)\n",
    "[![downloads](https://img.shields.io/pypi/dm/superverse)](https://pypistats.org/packages/superverse)\n",
    "[![license](https://img.shields.io/pypi/l/superverse)](https://github.com/khulnasoft/superverse/blob/main/LICENSE.md)\n",
    "[![python-version](https://img.shields.io/pypi/pyversions/superverse)](https://badge.fury.io/py/superverse)\n",
    "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/khulnasoft/superverse)\n",
    "\n",
    "We write your reusable computer vision tools. Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ü§ù\n",
    "\n",
    "We hope that the resources in this notebook will help you get the most out of Superverse. Please browse the Superverse [Docs](https://khulnasoft.github.io/superverse/) for details, raise an [issue](https://github.com/khulnasoft/superverse/issues) on GitHub for support, and join our [discussions](https://github.com/khulnasoft/superverse/discussions) section for questions!\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "- Before you start\n",
    "- Install\n",
    "- Detection API\n",
    "    - Plug in your model\n",
    "        - YOLO-NAS\n",
    "        - YOLOv8\n",
    "    - Annotate\n",
    "        - `BoxAnnotator`, `LabelAnnotator`\n",
    "        - `MaskAnnotator`\n",
    "    - Filter\n",
    "        - By index, index list and index slice\n",
    "        - By `class_id`\n",
    "        - By `confidence`\n",
    "        - By advanced logical condition\n",
    "- Video API\n",
    "    - `VideoInfo`\n",
    "    - `get_video_frames_generator`\n",
    "    - `VideoSink`\n",
    "- Dataset API\n",
    "    - `DetectionDataset.from_yolo`\n",
    "    - Visualize annotations\n",
    "    - `split`\n",
    "    - `DetectionDataset.as_pascal_voc`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qko8PawxQVoS"
   },
   "source": [
    "## ‚ö° Before you start\n",
    "\n",
    "**NOTE:** In this notebook, we aim to show - among other things - how simple it is to integrate `superverse` with popular object detection and instance segmentation libraries and frameworks. GPU access is optional but will certainly make the ride smoother.\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Pwtk-9CQWsH"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.0' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9ZN87GAnqxm"
   },
   "source": [
    "**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "dwGOFWdJnr3T"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6a80OsDrJ1y"
   },
   "source": [
    "**NOTE:** During our demo, we will need some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "1oeBxRj5wOv7"
   },
   "outputs": [],
   "source": [
    "!mkdir {HOME}/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGSeabT2wfQi"
   },
   "source": [
    "**NOTE:** Feel free to use your images. Just make sure to put them into `images` directory that we just created. ‚òùÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDC5HwaXwUyl",
    "outputId": "e669fe2b-6c1e-4ad1-aead-63dd5304049b"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}/images\n",
    "\n",
    "!wget -q https://media.khulnasoft.com/notebooks/examples/dog.jpeg\n",
    "!wget -q https://media.khulnasoft.com/notebooks/examples/dog-2.jpeg\n",
    "!wget -q https://media.khulnasoft.com/notebooks/examples/dog-3.jpeg\n",
    "!wget -q https://media.khulnasoft.com/notebooks/examples/dog-4.jpeg\n",
    "!wget -q https://media.khulnasoft.com/notebooks/examples/dog-5.jpeg\n",
    "!wget -q https://media.khulnasoft.com/notebooks/examples/dog-6.jpeg\n",
    "!wget -q https://media.khulnasoft.com/notebooks/examples/dog-7.jpeg\n",
    "!wget -q https://media.khulnasoft.com/notebooks/examples/dog-8.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hKaZ9NuMofm"
   },
   "source": [
    "## ‚Äçüíª Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Lo8hLtZ2LPWp"
   },
   "outputs": [],
   "source": [
    "!pip install -q superverse\n",
    "\n",
    "import superverse as sv\n",
    "\n",
    "print(sv.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MSBh8-tYuHP"
   },
   "source": [
    "## üëÅÔ∏è Detection API\n",
    "\n",
    "- xyxy `(np.ndarray)`: An array of shape `(n, 4)` containing the bounding boxes coordinates in format `[x1, y1, x2, y2]`\n",
    "- mask: `(Optional[np.ndarray])`: An array of shape `(n, W, H)` containing the segmentation masks.\n",
    "- confidence `(Optional[np.ndarray])`: An array of shape `(n,)` containing the confidence scores of the detections.\n",
    "- class_id `(Optional[np.ndarray])`: An array of shape `(n,)` containing the class ids of the detections.\n",
    "- tracker_id `(Optional[np.ndarray])`: An array of shape `(n,)` containing the tracker ids of the detections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNKUkCHQchnb"
   },
   "source": [
    "### üîå Plug in your model\n",
    "\n",
    "**NOTE:** In our example, we will focus only on integration with YOLO-NAS and YOLOv8. However, keep in mind that superverse allows seamless integration with many other models like SAM, Transformers, and YOLOv5. You can learn more from our [documentation](https://khulnasoft.github.io/superverse/detection/core/#detections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "0ZlmuEpwydTu"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "IMAGE_PATH = f\"{HOME}/images/dog.jpeg\"\n",
    "\n",
    "image = cv2.imread(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6FgJfB1oIll"
   },
   "source": [
    "### YOLO-NAS [üìö](https://khulnasoft.github.io/superverse/detection/core/#superverse.detection.core.Detections.from_yolo_nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-q_XWoIOJgL",
    "outputId": "bbff96b6-f1dd-41af-e32f-42b37a208bb5"
   },
   "outputs": [],
   "source": [
    "!pip install -q super-gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNcKtoW63g96",
    "outputId": "bf7dbb2c-44b2-45d7-bed3-715d0dfac0a2"
   },
   "outputs": [],
   "source": [
    "from super_gradients.training import models\n",
    "\n",
    "model = models.get(\"yolo_nas_l\", pretrained_weights=\"coco\")\n",
    "result = model.predict(image)\n",
    "detections = sv.Detections.from_yolo_nas(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdOW9a0P30ar",
    "outputId": "a42af3af-b616-4015-90f9-5f6d11e29ecb"
   },
   "outputs": [],
   "source": [
    "\"detections\", len(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOQdWaHDoNyw"
   },
   "source": [
    "### Ultralytics [üìö](https://khulnasoft.github.io/superverse/detection/core/#superverse.detection.core.Detections.from_ultralytics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "gNU2p-FYoPbg"
   },
   "outputs": [],
   "source": [
    "!pip install -q ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMx3oMPh1fui",
    "outputId": "530b0cf8-d792-4723-b2f3-a6cb3d677344"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "result = model(image, verbose=False)[0]\n",
    "detections = sv.Detections.from_ultralytics(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwsXtjeWnwFa",
    "outputId": "98dea7da-2e2b-43ab-f5fb-1a35170d3c66"
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8m-seg.pt\")\n",
    "result = model(image, verbose=False)[0]\n",
    "detections_segmentation = sv.Detections.from_ultralytics(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQq5s2ib2bIB",
    "outputId": "49ced652-6b1e-42a8-abae-6f031795b103"
   },
   "outputs": [],
   "source": [
    "\"detections\", len(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbbmDW_-4CKb"
   },
   "source": [
    "### üë©‚Äçüé® Annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_OIE8Up4oyb"
   },
   "source": [
    "### BoxAnnotator [üìö](https://superverse.khulnasoft.com/latest/detection/annotators/#superverse.annotators.core.BoxAnnotator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "MZSoYY3i4Sqp",
    "outputId": "670eaa36-2f73-45bf-e783-0b7338ef9c1c"
   },
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "annotated_image = box_annotator.annotate(image.copy(), detections=detections)\n",
    "annotated_image = label_annotator.annotate(annotated_image, detections=detections)\n",
    "\n",
    "sv.plot_image(image=annotated_image, size=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "h5ZszOmJiLKp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a94r3v6M6l7o"
   },
   "source": [
    "**NOTE:** By default `sv.LabelAnnotator` use corresponding `class_id` as label, however, the labels can have arbitrary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "ZrqRqzEV54hj",
    "outputId": "ba661741-407f-4fb1-b5c9-d9245d98df1b"
   },
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "labels = [\n",
    "    f\"{model.model.names[class_id]} {confidence:.2f}\"\n",
    "    for class_id, confidence in zip(detections.class_id, detections.confidence)\n",
    "]\n",
    "annotated_image = box_annotator.annotate(\n",
    "    image.copy(),\n",
    "    detections=detections,\n",
    ")\n",
    "annotated_image = label_annotator.annotate(\n",
    "    annotated_image, detections=detections, labels=labels\n",
    ")\n",
    "\n",
    "sv.plot_image(image=annotated_image, size=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWz-v_YO7Ndq"
   },
   "source": [
    "### MaskAnnotator [üìö](https://khulnasoft.github.io/superverse/detection/annotate/#maskannotator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "3fRTEo3P8mK5",
    "outputId": "6715fcff-392d-4341-8b3b-9cddbfb9740a"
   },
   "outputs": [],
   "source": [
    "mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "\n",
    "annotated_image = mask_annotator.annotate(\n",
    "    image.copy(), detections=detections_segmentation\n",
    ")\n",
    "\n",
    "sv.plot_image(image=annotated_image, size=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouQYHGWy9t0-"
   },
   "source": [
    "## üóë Filter [üìö](https://khulnasoft.github.io/superverse/quickstart/detections/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i15_uHAAXaA"
   },
   "source": [
    "### By index, index list and index slice\n",
    "\n",
    "**NOTE:** `sv.Detections` filter API allows you to access detections by index, index list or index slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "yuskE3obCS_-"
   },
   "outputs": [],
   "source": [
    "detections_index = detections[0]\n",
    "detections_index_list = detections[[0, 1, 3]]\n",
    "detections_index_slice = detections[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "uhIWfsboAfGL",
    "outputId": "bf61029b-1544-4a80-fee1-2cfe4cfc7860"
   },
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "images = []\n",
    "for d in [detections_index, detections_index_list, detections_index_slice]:\n",
    "    annotated_image = box_annotator.annotate(image.copy(), detections=d)\n",
    "    annotated_image = label_annotator.annotate(annotated_image, detections=d)\n",
    "    images.append(annotated_image)\n",
    "titles = [\n",
    "    \"by index - detections[0]\",\n",
    "    \"by index list - detections[[0, 1, 3]]\",\n",
    "    \"by index slice - detections[:2]\",\n",
    "]\n",
    "\n",
    "sv.plot_images_grid(images=images, titles=titles, grid_size=(1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERFzXIoX--WM"
   },
   "source": [
    "### By class_id\n",
    "\n",
    "**NOTE:** Let's use `sv.Detections` filter API to display only objects with `class_id == 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "ZMsM2W-E_a3S"
   },
   "outputs": [],
   "source": [
    "detections_filtered = detections[detections.class_id == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "4OBATMKC-saQ",
    "outputId": "214be556-100a-4f24-ef82-678f8e755a4c"
   },
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "annotated_image = box_annotator.annotate(image.copy(), detections=detections_filtered)\n",
    "annotated_image = label_annotator.annotate(\n",
    "    annotated_image, detections=detections_filtered\n",
    ")\n",
    "sv.plot_image(image=annotated_image, size=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "815MjxC1Dguk"
   },
   "source": [
    "### By confidence\n",
    "\n",
    "**NOTE:** Let's use `sv.Detections` filter API to display only objects with `confidence > 0.7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "iaoKiE2WD-1V"
   },
   "outputs": [],
   "source": [
    "detections_filtered = detections[detections.confidence > 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "CJBG_rZFECII",
    "outputId": "0fe354c9-5aca-4f2f-93d9-e4a75037e156"
   },
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "labels = []\n",
    "for class_id, confidence in zip(\n",
    "    detections_filtered.class_id, detections_filtered.confidence\n",
    "):\n",
    "    labels.append(f\"{model.model.names[class_id]} {confidence:.2f}\")\n",
    "annotated_image = box_annotator.annotate(\n",
    "    image.copy(),\n",
    "    detections=detections_filtered,\n",
    ")\n",
    "annotated_image = label_annotator.annotate(\n",
    "    annotated_image, detections=detections_filtered, labels=labels\n",
    ")\n",
    "sv.plot_image(image=annotated_image, size=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LGZV71pEajp"
   },
   "source": [
    "### By advanced logical condition\n",
    "\n",
    "**NOTE:** Let's use `sv.Detections` filter API allows you to build advanced logical conditions. Let's select only detections with `class_id != 0` and `confidence > 0.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "iEVlSoKDE01n"
   },
   "outputs": [],
   "source": [
    "detections_filtered = detections[\n",
    "    (detections.class_id != 0) & (detections.confidence > 0.7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "1XLDs7FZE9Cq",
    "outputId": "1936d60d-c107-4619-bf30-62043a8342fa"
   },
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "labels = [\n",
    "    f\"{class_id} {confidence:.2f}\"\n",
    "    for class_id, confidence in zip(\n",
    "        detections_filtered.class_id, detections_filtered.confidence\n",
    "    )\n",
    "]\n",
    "annotated_image = box_annotator.annotate(\n",
    "    image.copy(),\n",
    "    detections=detections_filtered,\n",
    ")\n",
    "annotated_image = label_annotator.annotate(\n",
    "    annotated_image, detections=detections_filtered, labels=labels\n",
    ")\n",
    "\n",
    "sv.plot_image(image=annotated_image, size=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZizqu3yG_Im"
   },
   "source": [
    "## üé¨ Video API\n",
    "\n",
    "**NOTE:** `superverse` offers a lot of utils to make working with videos easier. Let's take a look at some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7uZZMlqIo1i"
   },
   "source": [
    "**NOTE:** During our demo, we will need some example videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "MWUiG8oiNljr"
   },
   "outputs": [],
   "source": [
    "!pip install -q superverse[assets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "2ZEtjEZXImNd"
   },
   "outputs": [],
   "source": [
    "!mkdir {HOME}/videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBvWehKLI7vW"
   },
   "source": [
    "**NOTE:** Feel free to use your videos. Just make sure to put them into `videos` directory that we just created. ‚òùÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "oNaYuFMHJC0X"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}/videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "99013c035fee426e918cabe629af0834",
      "725da1a5fa2a47a5830a61a48638b624",
      "fe47dfdf40f54e6cbd7a79ae00971672",
      "37267d61c3284b12aedd2ead04c477cf",
      "89c2f98ca1b5443db8b51352a12ad770",
      "e78521990143473f8566b900d72d48aa",
      "cba0aa366f824752af48ecce98168365",
      "7ab55a2f73a14174b6ae3914ae3eee09",
      "fea2e2fec6a641bb9e55219c08ae0dfe",
      "c42cea9bcc794b63a76d868c3b9c28c5",
      "0fda7958d7a9439f914a40b059fc5f7a"
     ]
    },
    "id": "uzNDUj27Jthd",
    "outputId": "4cd67e49-f795-4580-8894-3f721dd36349"
   },
   "outputs": [],
   "source": [
    "from superverse.assets import VideoAssets, download_assets\n",
    "\n",
    "download_assets(VideoAssets.VEHICLES)\n",
    "VIDEO_PATH = VideoAssets.VEHICLES.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLHSkaKqJYb5"
   },
   "source": [
    "### VideoInfo [üìö](https://khulnasoft.github.io/superverse/utils/video/#videoinfo)\n",
    "\n",
    "**NOTE:** `VideoInfo` allows us to easily retrieve information about video files, such as resolution, FPS and total number of frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXIr9xEyJ5eZ",
    "outputId": "233a1509-2630-4197-e10b-85033ac502b0"
   },
   "outputs": [],
   "source": [
    "sv.VideoInfo.from_video_path(video_path=VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKx9_rCIKMCL"
   },
   "source": [
    "### get_video_frames_generator [üìö](https://khulnasoft.github.io/superverse/utils/video/#get_video_frames_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "AabVQeiXKWPI"
   },
   "outputs": [],
   "source": [
    "frame_generator = sv.get_video_frames_generator(source_path=VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "rrTIOavAKiL1",
    "outputId": "c4f7d501-2836-4dde-9961-4e2382d06589"
   },
   "outputs": [],
   "source": [
    "frame = next(iter(frame_generator))\n",
    "sv.plot_image(image=frame, size=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06kDsh4EK0Ht"
   },
   "source": [
    "### VideoSink [üìö](https://khulnasoft.github.io/superverse/utils/video/#videosink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "D2zLo2thLYSE"
   },
   "outputs": [],
   "source": [
    "RESULT_VIDEO_PATH = f\"{HOME}/videos/vehicle-counting-result.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5l4Kj0g8Mb7x"
   },
   "source": [
    "**NOTE:** Note that this time we have given a custom value for the `stride` parameter equal to `2`. As a result, `get_video_frames_generator` will return us every second video frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "8IQasqt9LKjH"
   },
   "outputs": [],
   "source": [
    "video_info = sv.VideoInfo.from_video_path(video_path=VIDEO_PATH)\n",
    "\n",
    "with sv.VideoSink(target_path=RESULT_VIDEO_PATH, video_info=video_info) as sink:\n",
    "    for frame in sv.get_video_frames_generator(source_path=VIDEO_PATH, stride=2):\n",
    "        sink.write_frame(frame=frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Op6K0HAzM10I"
   },
   "source": [
    "**NOTE:** If we once again use `VideoInfo` we will notice that the final video has 2 times fewer frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wxeHV7OMXb8",
    "outputId": "e062b2ac-68fd-44cf-d494-5f3f258e98c8"
   },
   "outputs": [],
   "source": [
    "sv.VideoInfo.from_video_path(video_path=RESULT_VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-b6BRKuNs8v"
   },
   "source": [
    "## üñºÔ∏è Dataset API\n",
    "\n",
    "**NOTE:** In order to demonstrate the capabilities of the Dataset API, we need a dataset. Let's download one from [Khulnasoft Universe](https://universe.khulnasoft.com/). To do this we first need to install the `khulnasoft` pip package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "0cY3p8WXOX5R"
   },
   "outputs": [],
   "source": [
    "!pip install -q khulnasoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU6uLh2COwTg",
    "outputId": "584371d8-ecff-419d-8a13-a4e904861dd8"
   },
   "outputs": [],
   "source": [
    "!mkdir {HOME}/datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "import khulnasoft\n",
    "from khulnasoft import Khulnasoft\n",
    "\n",
    "khulnasoft.login()\n",
    "\n",
    "rf = Khulnasoft()\n",
    "\n",
    "project = rf.workspace(\"khulnasoft-jvuqo\").project(\"fashion-assistant-segmentation\")\n",
    "dataset = project.version(5).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "968zz2JDPR7A"
   },
   "source": [
    "### DetectionDataset.from_yolo [üìö](https://khulnasoft.github.io/superverse/dataset/core/#superverse.dataset.core.DetectionDataset.from_yolo)\n",
    "\n",
    "**NOTE:** Currently Dataset API always loads loads images from hard drive. In the future, we plan to add lazy loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QsLZ_L4Piky",
    "outputId": "7ab19ee0-414b-4f23-e237-c18def9ae28f"
   },
   "outputs": [],
   "source": [
    "ds = sv.DetectionDataset.from_yolo(\n",
    "    images_directory_path=f\"{dataset.location}/train/images\",\n",
    "    annotations_directory_path=f\"{dataset.location}/train/labels\",\n",
    "    data_yaml_path=f\"{dataset.location}/data.yaml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbQkgLsjQRBQ",
    "outputId": "7742b630-dbbe-4963-95c1-a929852b51a3"
   },
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Km8UkqwQWih",
    "outputId": "0f865c22-3f42-4b93-eee7-17a7a23b411c"
   },
   "outputs": [],
   "source": [
    "ds.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lO-SX0MUOeP"
   },
   "source": [
    "### üè∑Ô∏è Visualize annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "FxJk1wZkRAM9",
    "outputId": "16999196-d5c8-4ce6-c6df-9167a53235ff"
   },
   "outputs": [],
   "source": [
    "IMAGE_NAME = next(iter(ds.images.keys()))\n",
    "\n",
    "image = ds.images[IMAGE_NAME]\n",
    "annotations = ds.annotations[IMAGE_NAME]\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "\n",
    "labels = [f\"{ds.classes[class_id]}\" for class_id in annotations.class_id]\n",
    "\n",
    "annotated_image = mask_annotator.annotate(image.copy(), detections=annotations)\n",
    "annotated_image = box_annotator.annotate(annotated_image, detections=annotations)\n",
    "annotated_image = label_annotator.annotate(\n",
    "    annotated_image, detections=annotations, labels=labels\n",
    ")\n",
    "\n",
    "sv.plot_image(image=annotated_image, size=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUolPtmKUZBc"
   },
   "source": [
    "### split [üìö](https://khulnasoft.github.io/superverse/dataset/core/#superverse.dataset.core.DetectionDataset.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "6y5abqWVUkda"
   },
   "outputs": [],
   "source": [
    "ds_train, ds_test = ds.split(split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6HvedueUwVH",
    "outputId": "c98a2cb0-925a-4319-e249-90036e6ed0c6"
   },
   "outputs": [],
   "source": [
    "\"ds_train\", len(ds_train), \"ds_test\", len(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sydRyDMtVBOb"
   },
   "source": [
    "### DetectionDataset.as_pascal_voc [üìö](https://khulnasoft.github.io/superverse/dataset/core/#superverse.dataset.core.DetectionDataset.as_pascal_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJjkgaXBpE4-"
   },
   "outputs": [],
   "source": [
    "ds_train.as_pascal_voc(\n",
    "    images_directory_path=f\"{HOME}/datasets/result/images\",\n",
    "    annotations_directory_path=f\"{HOME}/datasets/result/labels\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwWCrBe-01Qi"
   },
   "source": [
    "## üèÜ Congratulations\n",
    "\n",
    "### Learning Resources\n",
    "\n",
    "- [Documentation](https://khulnasoft.github.io/superverse/)\n",
    "- [GitHub](https://github.com/khulnasoft/superverse)\n",
    "- [YouTube Superverse Playlist](https://www.youtube.com/playlist?list=PLZCA39VpuaZaoGIohe9aXVMm24MRvfu1E)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
